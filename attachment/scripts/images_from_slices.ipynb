{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d14934a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import open3d as o3d\n",
    "import viser\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a86d95ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['points', 'plane', 'rgb', 'slice_corner', 'slice_center', 'max_points'])\n"
     ]
    }
   ],
   "source": [
    "#@title Importing the Clusters with It's radiances\n",
    "slices = torch.load(\"/workspace/FruitProposal/attachment/RadianceCloud/slice_points.pt\")\n",
    "print(slices.keys())\n",
    "\n",
    "planes  = slices['plane']\n",
    "points  = slices['points']\n",
    "rgbs    = slices['rgb']\n",
    "centers = slices['slice_center']\n",
    "corners = slices['slice_corner']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6561c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#server = viser.ViserServer()\n",
    "\n",
    "base_img = np.zeros(())\n",
    "\n",
    "_points = []\n",
    "_colors = []\n",
    "\n",
    "for k, point, plane, rgb in zip(range(len(points)),points, planes, rgbs):\n",
    "    # Create a point cloud\n",
    "    _slice = o3d.geometry.PointCloud()\n",
    "    _slice.points = o3d.utility.Vector3dVector(plane)\n",
    "    _slice.colors = o3d.utility.Vector3dVector(rgb)\n",
    "    \n",
    "    # Normalize the point cloud xn = x/z, yn = y/z, z = 1\n",
    "    _slice.points = o3d.utility.Vector3dVector(np.asarray(_slice.points) / np.asarray(_slice.points)[:, 2:3])\n",
    "\n",
    "    _points.append(np.asarray(_slice.points))\n",
    "    _colors.append(np.asarray(_slice.colors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94eeee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_resolution(num_points, min_size=(0,0)):\n",
    "    Wp = int(round((num_points)**0.5))\n",
    "    Hp = int(round(num_points / Wp))\n",
    "    Wp = max(Wp, min_size[0])\n",
    "    Hp = max(Hp, min_size[1])\n",
    "    return Wp, Hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a146dfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max points per slice: 607\n",
      "Image resolution x 512 y 512\n",
      "Points capacity 262144\n"
     ]
    }
   ],
   "source": [
    "f = lambda x : x.shape[0]\n",
    "\n",
    "max_points = max(map(f, _points))\n",
    "print(\"Max points per slice:\", max_points)\n",
    "\n",
    "# Obtaining image resolution\n",
    "W = np.sqrt(max_points*2).astype(int)\n",
    "\n",
    "W = 512\n",
    "\n",
    "print(\"Image resolution x\", W, \"y\", W)\n",
    "\n",
    "print(\"Points capacity\", W*W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2920704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordToPixel(coordW, extrinsic, intrinsic) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert world coordinates to pixel coordinates.\n",
    "    \"\"\"\n",
    "    coordW = np.array(coordW)\n",
    "    coordW = np.concatenate((coordW, np.ones((coordW.shape[0], 1))), axis=1)\n",
    "    coordC = (extrinsic @ coordW.T).T[:, :3]\n",
    "    coordP = (intrinsic @ coordC.T).T\n",
    "    coordP = coordP[:, :2] / coordP[:, 2:3]\n",
    "    return coordP.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f37dd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice 0 center → (u,v)=(256.00,256.00) — expected (256.00,256.00)\n",
      "Slice 1 center → (u,v)=(256.00,256.00) — expected (256.00,256.00)\n",
      "Slice 2 center → (u,v)=(256.00,256.00) — expected (256.00,256.00)\n",
      "Slice 3 center → (u,v)=(256.00,256.00) — expected (256.00,256.00)\n",
      "Slice 4 center → (u,v)=(256.00,256.00) — expected (256.00,256.00)\n",
      "Slice 5 center → (u,v)=(256.00,256.00) — expected (256.00,256.00)\n",
      "Slice 6 center → (u,v)=(256.00,256.00) — expected (256.00,256.00)\n",
      "Slice 7 center → (u,v)=(256.00,256.00) — expected (256.00,256.00)\n",
      "Slice 8 center → (u,v)=(256.00,256.00) — expected (256.00,256.00)\n"
     ]
    }
   ],
   "source": [
    "# Precompute intrinsics once\n",
    "z_cam = np.array([0, 0, -1])\n",
    "W = H = 512\n",
    "cx = W / 2\n",
    "cy = H / 2\n",
    "fxy = W\n",
    "intrinsic = np.array([\n",
    "    [fxy,   0,  cx],\n",
    "    [  0, fxy,  cy],\n",
    "    [  0,   0,   1]\n",
    "])\n",
    "\n",
    "for k, (pts, plane, rgb, corners_k, center_k) in enumerate(\n",
    "        zip(points, planes, rgbs, corners, centers, strict=False)):\n",
    "\n",
    "    # 1) elevar la slice por encima de Z=0\n",
    "    z0      = plane[:, 2].min()\n",
    "    shift_z = max(0.05 - z0, 0.0)\n",
    "\n",
    "    # 2) calcular R usando esquinas desplazadas\n",
    "    _corners = np.array(corners_k)\n",
    "    _corners[:, 2] += shift_z\n",
    "    e       = _corners[0] - _corners[1]\n",
    "    e_norm  = np.linalg.norm(e)\n",
    "    y_cam   = e / e_norm\n",
    "    x_cam   = np.cross(y_cam, z_cam);  x_cam /= np.linalg.norm(x_cam)\n",
    "    y_cam   = np.cross(z_cam, x_cam);  y_cam /= np.linalg.norm(y_cam)\n",
    "    R       = np.column_stack((x_cam, y_cam, z_cam))\n",
    "\n",
    "    # 3) posición inicial de la cámara\n",
    "    center_shift = center_k.copy()\n",
    "    center_shift[2] += shift_z\n",
    "    Ccam = center_shift + np.array([0, 0, e_norm])\n",
    "\n",
    "    # --- ajuste fino: centrar la proyección del centro del slice ---\n",
    "    Xc_center = R @ (center_shift - Ccam)\n",
    "    uvw_c     = intrinsic @ Xc_center\n",
    "    u_c, v_c  = uvw_c[0]/uvw_c[2], uvw_c[1]/uvw_c[2]\n",
    "    delta_u, delta_v = cx - u_c, cy - v_c\n",
    "\n",
    "    # pasar de píxeles a desplazamiento en el espacio de cámara\n",
    "    # un píxel en x corresponde a 1/fxy unidades en x_cam, igual para y\n",
    "    Ccam = Ccam - (delta_u / fxy) * x_cam - (delta_v / fxy) * y_cam\n",
    "\n",
    "    # 4) preparar lienzo\n",
    "    void_image = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "\n",
    "    # 5) proyectar cada punto\n",
    "    for pt, col in zip(plane, rgb):\n",
    "        p = pt.copy();  p[2] += shift_z\n",
    "        Xw_cam0 = p - Ccam\n",
    "        Xc      = R @ Xw_cam0\n",
    "        if Xc[2] <= 0:\n",
    "            continue\n",
    "\n",
    "        uvw = intrinsic @ Xc\n",
    "        u, v = uvw[0]/uvw[2], uvw[1]/uvw[2]\n",
    "        ui, vi = int(round(u)), int(round(v))\n",
    "        if 0 <= ui < W and 0 <= vi < H:\n",
    "            void_image[vi, ui] = (np.array(col)*255).astype(np.uint8)[::-1]\n",
    "\n",
    "    # 6) dilatar y guardar\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    out = cv2.dilate(void_image, kernel, iterations=5)\n",
    "    cv2.imwrite(f\"/workspace/FruitProposal/attachment/RadianceCloud/images/slice_{k}.png\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7558a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
